{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_factor_path = 'assets/movie_market.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>average_ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>9.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>9.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>8.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>8.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>8.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014</td>\n",
       "      <td>8.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>8.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012</td>\n",
       "      <td>7.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011</td>\n",
       "      <td>7.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010</td>\n",
       "      <td>7.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2009</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2008</td>\n",
       "      <td>7.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2007</td>\n",
       "      <td>6.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2006</td>\n",
       "      <td>6.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2005</td>\n",
       "      <td>6.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2004</td>\n",
       "      <td>6.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2003</td>\n",
       "      <td>6.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2002</td>\n",
       "      <td>5.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2001</td>\n",
       "      <td>5.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2000</td>\n",
       "      <td>5.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1999</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1998</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1997</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1996</td>\n",
       "      <td>4.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1995</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  average_ticket\n",
       "0   2019            9.11\n",
       "1   2018            9.11\n",
       "2   2017            8.97\n",
       "3   2016            8.65\n",
       "4   2015            8.43\n",
       "5   2014            8.17\n",
       "6   2013            8.13\n",
       "7   2012            7.96\n",
       "8   2011            7.93\n",
       "9   2010            7.89\n",
       "10  2009            7.50\n",
       "11  2008            7.18\n",
       "12  2007            6.88\n",
       "13  2006            6.55\n",
       "14  2005            6.41\n",
       "15  2004            6.21\n",
       "16  2003            6.03\n",
       "17  2002            5.81\n",
       "18  2001            5.66\n",
       "19  2000            5.39\n",
       "20  1999            5.08\n",
       "21  1998            4.69\n",
       "22  1997            4.59\n",
       "23  1996            4.42\n",
       "24  1995            4.35"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_html(avg_factor_path, encoding = 'utf-8'):\n",
    "    with open(avg_factor_path, \"r\", encoding = encoding) as f:\n",
    "        html_doc = f.read()\n",
    "    #     print(html_doc)\n",
    "        soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "        table = soup.find_all('table')[0] #the first table is the average factor table\n",
    "\n",
    "        table_rows = table.find_all('tr')[1:] #drop the first header\n",
    "        avg_data = []\n",
    "\n",
    "        for chunk in range(len(table_rows)):\n",
    "            chunk_res = table_rows[chunk].find_all('td')\n",
    "            year = int(chunk_res[0].text) #year in in the first td\n",
    "            avg_factor = float(chunk_res[-1].text.replace('$', '')) #year in in the last td\n",
    "            avg_data.append([year, avg_factor])\n",
    "    #         year = each_row.fina\n",
    "    #         print(row_year)\n",
    "    return avg_data\n",
    "    #         break\n",
    "    \n",
    "def sort_time_stamp(series):\n",
    "    dates = [datetime.datetime.strptime(entry, '%Y-%m-%d') for entry in series]\n",
    "    dates.sort()\n",
    "    sorted_dates = [datetime.datetime.strftime(entry, '%Y-%m-%d') for entry in dates]\n",
    "    return sorted_dates\n",
    "\n",
    "average_tickets = pd.DataFrame(parse_html(avg_factor_path), columns = ['year', 'average_ticket'])  \n",
    "average_tickets.to_csv('average_tickets.csv')\n",
    "#     table_row_break = table_row.text\n",
    "#     print(table_rows)\n",
    "average_tickets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "disney = pd.read_csv('disney_movies_info.csv')#.drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "# df.size()\n",
    "\n",
    "total_movie_box = pd.DataFrame({'date1': sort_time_stamp(disney.release_date),\n",
    "                                'value1': (disney.worldwide_earnings).astype(int),\n",
    "                                'movie1': disney.title})\n",
    "total_movie_box.to_json('assets/total_movie_box.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixar = pd.read_csv('pixar_movies_info.csv')\n",
    "\n",
    "total_moive_box2 = pd.DataFrame({'date2': sort_time_stamp(pixar.release_date),\n",
    "                                'value2': (pixar.worldwide_earnings).astype(int),\n",
    "                                'movie2': pixar.title})\n",
    "total_moive_box2.to_json('assets/total_moive_box2.json', orient='records')\n",
    "# total_movie_box.sort_values('value1', ascending = False).iloc[:10, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date2</th>\n",
       "      <th>value2</th>\n",
       "      <th>movie2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995-11-19</td>\n",
       "      <td>373554033</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-11-14</td>\n",
       "      <td>363258859</td>\n",
       "      <td>A Bug's Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-11-13</td>\n",
       "      <td>497366869</td>\n",
       "      <td>Toy Story 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-10-28</td>\n",
       "      <td>528773250</td>\n",
       "      <td>Monsters, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-05-30</td>\n",
       "      <td>871014978</td>\n",
       "      <td>Finding Nemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2004-10-27</td>\n",
       "      <td>631442092</td>\n",
       "      <td>The Incredibles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2006-03-14</td>\n",
       "      <td>461983149</td>\n",
       "      <td>Cars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007-06-22</td>\n",
       "      <td>623722818</td>\n",
       "      <td>Ratatouille</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008-06-21</td>\n",
       "      <td>521311860</td>\n",
       "      <td>WALL·E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009-05-13</td>\n",
       "      <td>735099082</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010-06-12</td>\n",
       "      <td>1066969703</td>\n",
       "      <td>Toy Story 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2011-06-18</td>\n",
       "      <td>559852396</td>\n",
       "      <td>Cars 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012-06-10</td>\n",
       "      <td>538983207</td>\n",
       "      <td>Brave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>743559607</td>\n",
       "      <td>Monsters University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-05-18</td>\n",
       "      <td>857611174</td>\n",
       "      <td>Inside Out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-11-10</td>\n",
       "      <td>332207671</td>\n",
       "      <td>The Good Dinosaur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016-06-08</td>\n",
       "      <td>1028570889</td>\n",
       "      <td>Finding Dory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-06-10</td>\n",
       "      <td>383930656</td>\n",
       "      <td>Cars 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>807082196</td>\n",
       "      <td>Coco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-06-05</td>\n",
       "      <td>1242805359</td>\n",
       "      <td>Incredibles 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>1073394593</td>\n",
       "      <td>Toy Story 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date2      value2               movie2\n",
       "0   1995-11-19   373554033            Toy Story\n",
       "1   1998-11-14   363258859         A Bug's Life\n",
       "2   1999-11-13   497366869          Toy Story 2\n",
       "3   2001-10-28   528773250       Monsters, Inc.\n",
       "4   2003-05-30   871014978         Finding Nemo\n",
       "5   2004-10-27   631442092      The Incredibles\n",
       "6   2006-03-14   461983149                 Cars\n",
       "7   2007-06-22   623722818          Ratatouille\n",
       "8   2008-06-21   521311860               WALL·E\n",
       "9   2009-05-13   735099082                   Up\n",
       "10  2010-06-12  1066969703          Toy Story 3\n",
       "11  2011-06-18   559852396               Cars 2\n",
       "12  2012-06-10   538983207                Brave\n",
       "13  2013-06-05   743559607  Monsters University\n",
       "14  2015-05-18   857611174           Inside Out\n",
       "15  2015-11-10   332207671    The Good Dinosaur\n",
       "16  2016-06-08  1028570889         Finding Dory\n",
       "17  2017-06-10   383930656               Cars 3\n",
       "18  2017-10-20   807082196                 Coco\n",
       "19  2018-06-05  1242805359        Incredibles 2\n",
       "20  2019-06-11  1073394593          Toy Story 4"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_moive_box2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
